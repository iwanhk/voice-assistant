{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a786c77c",
   "metadata": {},
   "source": [
    "# LangChain: Memory\n",
    "\n",
    "## Outline\n",
    "* ConversationBufferMemory\n",
    "* ConversationBufferWindowMemory\n",
    "* ConversationTokenBufferMemory\n",
    "* ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297dcd5",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2301270b-7a69-40f8-9934-f840499b6ae9",
   "metadata": {},
   "source": [
    "Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20ad6fe2",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from config import *\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88bdf13d",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = load(\"Tongyi\")\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db24677d",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 我是理文，你呢？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'我是来自阿里云的超大规模语言模型，你可以叫我通义千问。很高兴与你交流！在对话中，如果你有任何问题或需要帮助，请随时告诉我，我会尽力提供支持。'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"我是理文,你呢？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc3ef937",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 我是理文，你呢？\n",
      "AI: 我是来自阿里云的超大规模语言模型，你可以叫我通义千问。很高兴与你交流！在对话中，如果你有任何问题或需要帮助，请随时告诉我，我会尽力提供支持。\n",
      "Human: 天涯何处是归人？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'这句诗表达了游子对故乡的深深思念。\"天涯何处是归人\"出自唐朝诗人马戴的《塞下曲》，原句为\"落叶他乡树，寒灯独夜人。不知何处路，此夜宿沙尘。\"这里的\"归人\"指的是漂泊在外的游子，他们在遥远的地方寻找着回家的路。这首诗描绘了旅人的孤独和思乡之情。如果你有关于诗词、文化或者需要解读诗句方面的帮助，我很乐意提供。'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"天涯何处是归人？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acf3339a",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 我是理文，你呢？\n",
      "AI: 我是来自阿里云的超大规模语言模型，你可以叫我通义千问。很高兴与你交流！在对话中，如果你有任何问题或需要帮助，请随时告诉我，我会尽力提供支持。\n",
      "Human: 天涯何处是归人？\n",
      "AI: 这句诗表达了游子对故乡的深深思念。\"天涯何处是归人\"出自唐朝诗人马戴的《塞下曲》，原句为\"落叶他乡树，寒灯独夜人。不知何处路，此夜宿沙尘。\"这里的\"归人\"指的是漂泊在外的游子，他们在遥远的地方寻找着回家的路。这首诗描绘了旅人的孤独和思乡之情。如果你有关于诗词、文化或者需要解读诗句方面的帮助，我很乐意提供。\n",
      "Human: 我叫什么？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你自我介绍为“理文”，但具体的名字我没有记录。如果你需要，我们可以随意为你起个昵称，或者你也可以告诉我你的真名，我会更好地记住。'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"我叫什么？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2529400d",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 我是理文，你呢？\n",
      "AI: 我是来自阿里云的超大规模语言模型，你可以叫我通义千问。很高兴与你交流！在对话中，如果你有任何问题或需要帮助，请随时告诉我，我会尽力提供支持。\n",
      "Human: 天涯何处是归人？\n",
      "AI: 这句诗表达了游子对故乡的深深思念。\"天涯何处是归人\"出自唐朝诗人马戴的《塞下曲》，原句为\"落叶他乡树，寒灯独夜人。不知何处路，此夜宿沙尘。\"这里的\"归人\"指的是漂泊在外的游子，他们在遥远的地方寻找着回家的路。这首诗描绘了旅人的孤独和思乡之情。如果你有关于诗词、文化或者需要解读诗句方面的帮助，我很乐意提供。\n",
      "Human: 我叫什么？\n",
      "AI: 你自我介绍为“理文”，但具体的名字我没有记录。如果你需要，我们可以随意为你起个昵称，或者你也可以告诉我你的真名，我会更好地记住。\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5018cb0a",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 我是理文，你呢？\\nAI: 我是来自阿里云的超大规模语言模型，你可以叫我通义千问。很高兴与你交流！在对话中，如果你有任何问题或需要帮助，请随时告诉我，我会尽力提供支持。\\nHuman: 天涯何处是归人？\\nAI: 这句诗表达了游子对故乡的深深思念。\"天涯何处是归人\"出自唐朝诗人马戴的《塞下曲》，原句为\"落叶他乡树，寒灯独夜人。不知何处路，此夜宿沙尘。\"这里的\"归人\"指的是漂泊在外的游子，他们在遥远的地方寻找着回家的路。这首诗描绘了旅人的孤独和思乡之情。如果你有关于诗词、文化或者需要解读诗句方面的帮助，我很乐意提供。\\nHuman: 我叫什么？\\nAI: 你自我介绍为“理文”，但具体的名字我没有记录。如果你需要，我们可以随意为你起个昵称，或者你也可以告诉我你的真名，我会更好地记住。'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14219b70",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a36e9905",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"你好\"}, \n",
    "                    {\"output\": \"今天怎么样？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61631b1f",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 你好\n",
      "AI: 今天怎么样？\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2fdf9ec",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好\\nAI: 今天怎么样？'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ca79256",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"还行吧,你呢？\"}, \n",
    "                    {\"output\": \"活着\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "890a4497",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好\\nAI: 今天怎么样？\\nHuman: Not much, just hanging\\nAI: Cool\\nHuman: 还行吧，你呢？\\nAI: 活着\\nHuman: 还行吧，你呢？\\nAI: 活着'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf98e9ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66eeccc3",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ea6233e",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc4553fb",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"你好\"},\n",
    "                    {\"output\": \"你好,今天怎么样\"})\n",
    "memory.save_context({\"input\": \"还行吧,你呢？\"},\n",
    "                    {\"output\": \"活着\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a788403",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 还行吧，你呢？\\nAI: 活着'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4087bc87",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = load(\"Tongyi\")\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4faaa952",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好，理文！很高兴与你交谈。我是一个AI助手，专门设计来提供信息和帮助解答问题。有什么我可以为你效劳的吗？'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"我是理文\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb20ddaa",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'这句诗表达了游子对故乡的深深思念。\"天涯何处是归人\"出自唐代诗人马戴的《灞上秋居》，意思是茫茫人世间，哪里才是我真正的归宿呢？如果你对这首诗或者中国古代文学有兴趣，我可以帮你深入了解。'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"天涯何处是归人？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "489b2194",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'很抱歉，由于我是一个人工智能，我并不具备获取或存储个人身份信息的能力。我无法告诉你你的名字，除非你主动提供。如果你需要，我们可以聊聊其他话题。'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"我叫什么？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2931b92",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f6d063c",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb9020ed",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "llm = load(\"Tongyi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43582ee6",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)\n",
    "memory.save_context({\"input\": \"你好\"},\n",
    "                    {\"output\": \"你好,今天怎么样\"})\n",
    "memory.save_context({\"input\": \"还行吧,你呢？\"},\n",
    "                    {\"output\": \"活着\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "284288e1",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: 你好，今天怎么样\\nHuman: 还行吧，你呢？\\nAI: 活着'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff55d5d",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "72dcf8b1",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a5b238f",
   "metadata": {
    "height": 268,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a long string\n",
    "docs = \"\"\"\n",
    "智慧文旅门票\n",
    "随着元宇宙,AIGC等技术的成熟,文旅行业正进入数字化的快车道。门票,既是连接用户和景区最重要的凭证,也是串联各种数字化服务升级良好的纽带。我们选择用元宇宙和AIGC技术打造全新的数字门票,并且联合央视台在春晚做了全国首次“摇一摇送智慧文旅门票”的口播,覆盖了全国主要景区,开创了数字化文旅的新局面。\n",
    "智慧文旅门票与传统纸质门票和互联网平台的数字门票有着明显的区别。首先,智慧文旅门票是一个真正意义上的数字资产,它可以打通各个平台,让用户真正拥有资产,让景区真正拥有用户。每张门票都可以在数字原生资产浏览器上登记注册,实现公开透明,为景区数字资产的估值、数字资产并表和贷款等金融操作打下基础。\n",
    "为了为数字门票提供有力的技术支持,我们选择了ERC6551标准。这一标准在兼容ERC721的基础上,为门票提供了更多的属性和功能,如有效期、核销、动态属性、门票组合和通票选择等。这使得智慧文旅门票具有多个权益核销点,可以在景区内形成打卡点组合。也可以通过链上分账做到大小景区互相引流,共享游客,增量创收。这一标准的引入是对智慧文旅门票发行和管理的重大创新。\n",
    "生成式AIGC技术的成熟,已经可以智能得回答用户的各种问题,智慧文旅门票为每个景区都配备了AI小助手,通过私域数据的训练,可以完成从旅游行程安排,到景区信息问答,到周边生活建议等等多种功能。完整地配合每个用户的票务选择和出行。目前,全国各景区的数据正在训练中,很快就会有全面的智能服务。我们正在开发的智能AI助手,更可以配合出行拍摄文旅短视频,甚至短剧,让每个人都成为创作者。\n",
    "元宇宙的数字体验也逐渐成为大众消费者的选择。\n",
    "\"\"\"\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"你好\"},\n",
    "                    {\"output\": \"你好,今天怎么样\"})\n",
    "memory.save_context({\"input\": \"还行吧,你呢？\"},\n",
    "                    {\"output\": \"活着\"})\n",
    "memory.save_context({\"input\": \"智慧门票是什么？\"}, \n",
    "                    {\"output\": f\"{docs}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e4ecabe",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human greets the AI and inquires about its well-being. The AI explains that it\\'s functioning well and introduces the concept of \"智慧文旅门票\" - a digital ticket facilitated by emerging technologies like元宇宙 (Metaverse) and AIGC. These tickets act as a digital asset, providing transparent and verifiable ownership, with features like ERC6551 standard for enhanced functionality and interoperability between platforms. AI-generated content through AIGC enables personalized assistance for tourists, from itinerary planning to immersive experiences like VR tours. The tickets can be used across multiple sites and combined with other content IPs, such as VR experiences and cultural content. The system also offers direct booking through blockchain-based小程序 and seamless entry via identity verification. The initiative has received significant support from provincial文旅部门, with over 67 participating venues and 2 million tickets issued during the春晚 promotion. The project aims to create a more open, transparent, and trustworthy digital ecosystem in the文化旅游 industry, and the AI expresses a desire for further collaborations.'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6728edba",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a221b1d",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human greets the AI and inquires about its well-being. The AI explains that it's functioning well and introduces the concept of \"智慧文旅门票\" - a digital ticket facilitated by emerging technologies like元宇宙 (Metaverse) and AIGC. These tickets act as a digital asset, providing transparent and verifiable ownership, with features like ERC6551 standard for enhanced functionality and interoperability between platforms. AI-generated content through AIGC enables personalized assistance for tourists, from itinerary planning to immersive experiences like VR tours. The tickets can be used across multiple sites and combined with other content IPs, such as VR experiences and cultural content. The system also offers direct booking through blockchain-based小程序 and seamless entry via identity verification. The initiative has received significant support from provincial文旅部门, with over 67 participating venues and 2 million tickets issued during the春晚 promotion. The project aims to create a more open, transparent, and trustworthy digital ecosystem in the文化旅游 industry, and the AI expresses a desire for further collaborations.\n",
      "Human: 智慧门票好吗？\n",
      "AI:\u001b[0m\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 712, in urlopen\n",
      "    destination_scheme = parsed_url.scheme\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 1012, in _prepare_proxy\n",
      "    port,\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/urllib3/connection.py\", line 419, in connect\n",
      "    self.send(b\"0\\r\\n\\r\\n\")\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/urllib3/util/ssl_.py\", line 449, in ssl_wrap_socket\n",
      "    # keyfile being encrypted and OpenSSL asking for the\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/urllib3/util/ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
      "    def _ssl_wrap_socket_impl(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py\", line 500, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py\", line 1040, in _create\n",
      "    self.do_handshake()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py\", line 1309, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1129)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 799, in urlopen\n",
      "    headers=headers,\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/urllib3/util/retry.py\", line 592, in increment\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='dashscope.aliyuncs.com', port=443): Max retries exceeded with url: /api/v1/services/aigc/text-generation/generation (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/vz/jy2yy15908s75x4cj9j1yb180000gn/T/ipykernel_50492/2889232596.py\", line 1, in <module>\n",
      "    conversation.predict(input=\"智慧门票好吗？\")\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain/chains/llm.py\", line 293, in predict\n",
      "    return self(kwargs, callbacks=callbacks)[self.output_key]\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain_core/_api/deprecation.py\", line 145, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain/chains/base.py\", line 378, in __call__\n",
      "    return self.invoke(\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain/chains/base.py\", line 163, in invoke\n",
      "    raise e\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain/chains/base.py\", line 158, in invoke\n",
      "    final_outputs: Dict[str, Any] = self.prep_outputs(\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain/chains/base.py\", line 455, in prep_outputs\n",
      "    self.memory.save_context(inputs, outputs)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain/memory/summary_buffer.py\", line 60, in save_context\n",
      "    self.prune()\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain/memory/summary_buffer.py\", line 71, in prune\n",
      "    self.moving_summary_buffer = self.predict_new_summary(\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain/memory/summary.py\", line 35, in predict_new_summary\n",
      "    return chain.predict(summary=existing_summary, new_lines=new_lines)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain/chains/llm.py\", line 293, in predict\n",
      "    return self(kwargs, callbacks=callbacks)[self.output_key]\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain_core/_api/deprecation.py\", line 145, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain/chains/base.py\", line 378, in __call__\n",
      "    return self.invoke(\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain/chains/base.py\", line 163, in invoke\n",
      "    raise e\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain/chains/base.py\", line 153, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain/chains/llm.py\", line 103, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain/chains/llm.py\", line 115, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\", line 544, in generate_prompt\n",
      "    for res in results\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\", line 408, in generate\n",
      "    self.tags,\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\", line 398, in generate\n",
      "    prompt and additional model provider-specific output.\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\", line 577, in _generate_with_cache\n",
      "    callbacks: Callbacks = None,\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain_community/chat_models/tongyi.py\", line 283, in _generate\n",
      "    resp = self.completion_with_retry(**params)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain_community/chat_models/tongyi.py\", line 215, in completion_with_retry\n",
      "    return _completion_with_retry(**kwargs)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/tenacity/__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/tenacity/__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/tenacity/__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py\", line 439, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/tenacity/__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/langchain_community/chat_models/tongyi.py\", line 212, in _completion_with_retry\n",
      "    resp = self.client.call(**_kwargs)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/dashscope/aigc/generation.py\", line 136, in call\n",
      "    response = super().call(model=model,\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/dashscope/client/base_api.py\", line 135, in call\n",
      "    return request.call()\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/dashscope/api_entities/http_request.py\", line 76, in call\n",
      "    output = next(response)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/dashscope/api_entities/http_request.py\", line 222, in _handle_request\n",
      "    raise e\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/dashscope/api_entities/http_request.py\", line 205, in _handle_request\n",
      "    response = session.post(url=self.url,\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/requests/adapters.py\", line 517, in send\n",
      "    raise SSLError(e, request=request)\n",
      "requests.exceptions.SSLError: HTTPSConnectionPool(host='dashscope.aliyuncs.com', port=443): Max retries exceeded with url: /api/v1/services/aigc/text-generation/generation (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/iwan/work/AI/lib/python3.9/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"智慧门票好吗？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb582617",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human greets the AI and inquires about the AI's plans for the day. The AI responds casually, mentioning a morning meeting with the product team where a well-prepared PowerPoint presentation is needed. From 9am to 12pm, the AI suggests working on the LangChain project, emphasizing its efficiency due to the tool's power. The AI has scheduled a lunch meeting with a customer who will travel long distances to discuss AI advancements. The AI advises showing the AI's language translation capabilities during the meeting, demonstrating real-time translations, accuracy, and quick response generation to impress the client. The AI also recommends highlighting recent improvements in the LLM model for a compelling demonstration.\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6709b89-182e-4b7b-b811-1584dda20652",
   "metadata": {},
   "source": [
    "Reminder: Download your notebook to you local computer to save your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba827aa",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c07922b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52696c8c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48690d13",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bba1f8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a62e89",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f953ad8d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb2617",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1989bf",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8dca6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9120949",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55849fb5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae491b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3aec3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae51a3f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06894001",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb674c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5158f4c8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cebe066",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65caee4d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04799230",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30795c10",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed59c4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb43eee3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
